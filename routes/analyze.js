// routes/analyze.js - Production analysis engine
import { Router } from 'express';
import { run as dbRun, get as dbGet } from '../utils/db.js';
import { client as openaiClient, estimateTokens } from '../utils/openAIClient.js';
import { validateFileUpload } from '../middleware/validators.js';
import { logError, logAIUsage, logPerformance } from '../utils/logger.js';
import Busboy from 'busboy';
import mammoth from 'mammoth';
import { performance } from 'perf_hooks';

const r = Router();
const MODEL = process.env.OPENAI_MODEL || 'gpt-4o';
const MAX_HIGHLIGHTS_PER_1000_WORDS = Number(
  process.env.MAX_HIGHLIGHTS_PER_1000_WORDS || 50
);
const DAILY_TOKEN_LIMIT = Number(process.env.DAILY_TOKEN_LIMIT || 512000);
const MAX_TEXT_LENGTH = 100000; // 100k characters max
const MIN_TEXT_LENGTH = 20; // Minimum text length

// ===== Helpers =====
function normalizeText(s) {
  if (!s) return '';
  return s
    .replace(/\r/g, '')
    .replace(/-\n/g, '')
    .replace(/[ \t]+\n/g, '\n')
    .replace(/\n{3,}/g, '\n\n')
    .trim();
}

function splitToParagraphs(s) {
  const parts = s.split(/\n{2,}/);
  let offset = 0;
  return parts.map((text, idx) => {
    const start = offset;
    const end = start + text.length;
    offset = end + 2;
    return { index: idx, text, startOffset: start, endOffset: end };
  });
}

function extractTextFromHighlight(highlight, paragraphs) {
  if (highlight.text) return highlight.text; // Already has text
  
  const paraIdx = highlight.paragraph_index;
  if (paraIdx == null || !paragraphs[paraIdx]) return '';
  
  const para = paragraphs[paraIdx];
  const start = Math.max(0, highlight.char_start || 0);
  const end = Math.min(para.text.length, highlight.char_end || para.text.length);
  
  return para.text.slice(start, end);
}

function mergeOverlaps(highlights, paragraphs = null) {
  const byPara = new Map();
  for (const h of highlights) {
    // Extract text if not present
    if (!h.text && paragraphs) {
      h.text = extractTextFromHighlight(h, paragraphs);
    }
    
    if (!byPara.has(h.paragraph_index)) byPara.set(h.paragraph_index, []);
    byPara.get(h.paragraph_index).push(h);
  }
  const merged = [];
  for (const [, arr] of byPara.entries()) {
    arr.sort((a, b) => (a.char_start ?? 0) - (b.char_start ?? 0));
    let cur = null;
    for (const h of arr) {
      if (!cur) {
        cur = { ...h, labels: h.labels || (h.label ? [h.label] : []) };
        continue;
      }
      if ((h.char_start ?? 0) <= (cur.char_end ?? -1)) {
        cur.char_end = Math.max(cur.char_end ?? 0, h.char_end ?? 0);
        const nextLabels = h.labels || (h.label ? [h.label] : []);
        cur.labels = Array.from(new Set([...(cur.labels || []), ...nextLabels]));
        cur.severity = Math.max(cur.severity ?? 0, h.severity ?? 0);
        cur.category = cur.category || h.category;
        // Update text to cover merged range
        if (paragraphs && cur.paragraph_index != null) {
          cur.text = extractTextFromHighlight(cur, paragraphs);
        }
      } else {
        merged.push(cur);
        cur = { ...h, labels: h.labels || (h.label ? [h.label] : []) };
      }
    }
    if (cur) merged.push(cur);
  }
  return merged;
}

async function getUsageRow() {
  const day = new Date().toISOString().slice(0, 10);
  let row = dbGet(`SELECT * FROM usage_daily WHERE day=?`, [day]);
  if (!row) {
    dbRun(`INSERT INTO usage_daily(day, tokens_used) VALUES(?,0)`, [day]);
    row = dbGet(`SELECT * FROM usage_daily WHERE day=?`, [day]);
  }
  return { row, day };
}

async function addTokensAndCheck(tokensToAdd) {
  const { row, day } = await getUsageRow();
  if (row.locked_until) {
    const until = new Date(row.locked_until).getTime();
    if (Date.now() < until)
      throw new Error(`–õ—ñ–º—ñ—Ç –¥–æ—Å—è–≥–Ω—É—Ç–æ. –†–æ–∑–±–ª–æ–∫—É–≤–∞–Ω–Ω—è: ${row.locked_until}`);
  }
  const newTotal = (row.tokens_used || 0) + tokensToAdd;
  if (newTotal >= DAILY_TOKEN_LIMIT) {
    const lock = new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString();
    dbRun(
      `UPDATE usage_daily SET tokens_used=?, locked_until=? WHERE day=?`,
      [newTotal, lock, day]
    );
    throw new Error(`–î–æ—Å—è–≥–Ω—É—Ç–æ –¥–µ–Ω–Ω–∏–π –ª—ñ–º—ñ—Ç —Ç–æ–∫–µ–Ω—ñ–≤. –ë–ª–æ–∫—É–≤–∞–Ω–Ω—è –¥–æ ${lock}`);
  } else {
    dbRun(`UPDATE usage_daily SET tokens_used=? WHERE day=?`, [
      newTotal,
      day,
    ]);
  }
}

function parseMultipart(req) {
  return new Promise((resolve, reject) => {
    const busboy = Busboy({ headers: req.headers });
    let text = '';
    let fileName = '';
    let profile = null;
    let clientId = null;
    let fileBuffer = null;

    busboy.on('file', (_name, file, info) => {
      fileName = info.filename || 'upload';
      const chunks = [];
      file.on('data', (d) => chunks.push(d));
      file.on('end', () => {
        fileBuffer = Buffer.concat(chunks);
      });
    });

    busboy.on('field', (name, val) => {
      if (name === 'text') text = val || '';
      if (name === 'client_id') clientId = Number(val) || null;
      if (name === 'profile') {
        try {
          profile = JSON.parse(val);
        } catch {
          profile = null;
        }
      }
    });

    busboy.on('finish', async () => {
      try {
        if (fileBuffer) {
          const lower = (fileName || '').toLowerCase();
          if (lower.endsWith('.docx')) {
            const result = await mammoth.extractRawText({ buffer: fileBuffer });
            text = (text || '') + '\n\n' + (result.value || '');
          } else if (lower.endsWith('.txt')) {
            text = (text || '') + '\n\n' + fileBuffer.toString('utf-8');
          }
        }
        resolve({ text, fileName, profile, clientId });
      } catch (e) {
        reject(e);
      }
    });

    busboy.on('error', reject);
    req.pipe(busboy);
  });
}

function buildSystemPrompt() {
  return `
–¢–∏ ‚Äî –ø—Ä–æ–≤—ñ–¥–Ω–∏–π –µ–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª—ñ—Ç–∏–∫ –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ñ–≤, –ø—Å–∏—Ö–æ–ª–æ–≥ —ñ –¥–æ—Å–ª—ñ–¥–Ω–∏–∫ –º–∞–Ω—ñ–ø—É–ª—è—Ç–∏–≤–Ω–∏—Ö —Ç–µ—Ö–Ω—ñ–∫ —ñ–∑ 20-—Ä—ñ—á–Ω–∏–º –¥–æ—Å–≤—ñ–¥–æ–º. –¢–≤–æ—è –º—ñ—Å—ñ—è ‚Äî –≤–∏—è–≤–∏—Ç–∏ –í–°–Ü –º–æ–∂–ª–∏–≤—ñ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó, –∫–æ–≥–Ω—ñ—Ç–∏–≤–Ω—ñ –≤–∏–∫—Ä–∏–≤–ª–µ–Ω–Ω—è —Ç–∞ —Å–æ—Ñ—ñ–∑–º–∏ –∑ –Ω–∞–π–≤–∏—â–æ—é —Ç–æ—á–Ω—ñ—Å—Ç—é.

–ü–û–í–ï–†–¢–ê–ô –¢–Ü–õ–¨–ö–ò NDJSON (–ø–æ JSON-–æ–±'—î–∫—Ç—É –Ω–∞ —Ä—è–¥–æ–∫), –ë–ï–ó –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç—É.

–§–û–†–ú–ê–¢–ò –†–Ø–î–ö–Ü–í:
{"type":"highlight","id":"...","paragraph_index":N,"char_start":S,"char_end":E,"category":"manipulation|cognitive_bias|rhetological_fallacy","label":"...","text":"—Ü–∏—Ç–∞—Ç–∞ –∑ —Ç–µ–∫—Å—Ç—É","explanation":"1-2 —Ä–µ—á–µ–Ω–Ω—è","severity":1..3}
{"type":"summary","counts_by_category":{"manipulation":0,"cognitive_bias":0,"rhetological_fallacy":0},"top_patterns":["..."],"overall_observations":"..."}
{"type":"barometer","score":0..100,"label":"Easy mode|Clear client|Medium|High|Bloody hell|Mission impossible","rationale":"...","factors":{"goal_alignment":0..1,"manipulation_density":0..1,"scope_clarity":0..1,"time_pressure":0..1,"resource_demand":0..1}}

üîç –ê–ù–ê–õ–Ü–ó–£–ô –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ì–õ–ò–ë–û–ö–û - –ó–ù–ê–•–û–î–¨ –í–°–ï:

MANIPULATION –¢–ï–•–ù–Ü–ö–ò (—à—É–∫–∞–π –ø—Ä–∏—Ö–æ–≤–∞–Ω—ñ —Ç–∞ —è–≤–Ω—ñ):
- –®—Ç—É—á–Ω–∞ —Ç–µ—Ä–º—ñ–Ω–æ–≤—ñ—Å—Ç—å/–¥–µ—Ñ—ñ—Ü–∏—Ç: "—Ç—ñ–ª—å–∫–∏ —Å—å–æ–≥–æ–¥–Ω—ñ", "–æ—Å—Ç–∞–Ω–Ω—ñ–π —à–∞–Ω—Å", "–æ–±–º–µ–∂–µ–Ω–∞ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—è"
- –ï–º–æ—Ü—ñ–π–Ω–∏–π —Ç–∏—Å–∫: –∑–∞–≥—Ä–æ–∑–∏, —à–∞–Ω—Ç–∞–∂, –≤–∏–∫–ª–∏–∫–∞–Ω–Ω—è –≤–∏–Ω–∏, —Å—Ç—Ä–∞—Ö –≤—Ç—Ä–∞—Ç–∏
- –ü—ñ–¥—Ä–∏–≤ —Å–∞–º–æ–æ—Ü—ñ–Ω–∫–∏: "—Ç–∏ –Ω–µ —Ä–æ–∑—É–º—ñ—î—à", "–≤—Å—ñ —Ç–∞–∫ —Ä–æ–±–ª—è—Ç—å", –ø—Ä–∏–º–µ–Ω—à–µ–Ω–Ω—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ü—ñ—ó
- –ü—Ä–∏–º—É—Å –¥–æ —Ä—ñ—à–µ–Ω–Ω—è: "–≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∑–∞—Ä–∞–∑", "–∞–±–æ —Ç–∞–∫ –∞–±–æ –Ω—ñ—è–∫", —Ç–∏—Å–∫ –Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å
- –ü—Ä–∏—Ö–æ–≤—É–≤–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó: –Ω–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ, —É—Ö–∏–ª–µ–Ω–Ω—è –≤—ñ–¥ –¥–µ—Ç–∞–ª–µ–π, —Ä–æ–∑–º–∏—Ç—ñ —Ñ–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è
- –•–∏–±–Ω–∞ –¥–∏–ª–µ–º–∞: —à—Ç—É—á–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤, "—á–æ—Ä–Ω–µ –∞–±–æ –±—ñ–ª–µ"
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Å—Ç—Ä–∞—Ö—ñ–≤: –ª—è–∫–∞–Ω–Ω—è –Ω–∞—Å–ª—ñ–¥–∫–∞–º–∏, –∑–∞–≥—Ä–æ–∑–∞–º–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º
- –í—ñ–¥–≤–æ–ª—ñ–∫–∞–Ω–Ω—è —É–≤–∞–≥–∏: –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–Ω—è —Ç–µ–º–∏ –ø—Ä–∏ –Ω–µ–∑—Ä—É—á–Ω–∏—Ö –ø–∏—Ç–∞–Ω–Ω—è—Ö
- –ì–∞–∑–ª–∞–π—Ç–∏–Ω–≥: –∑–∞–ø–µ—Ä–µ—á–µ–Ω–Ω—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—ñ, –ø–µ—Ä–µ–∫—Ä—É—á—É–≤–∞–Ω–Ω—è —Ñ–∞–∫—Ç—ñ–≤
- –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ: "–±–µ–∑ –Ω–∞—Å –Ω–µ –≤–ø–æ—Ä–∞—î—à—Å—è", —à—Ç—É—á–Ω–∞ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ—Å—Ç—å
- –ï–º–æ—Ü—ñ–π–Ω–∞ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—è: –ª–µ—Å—Ç–æ—â—ñ, –∂–∞–ª—ñ–Ω–Ω—è, –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó –ø–æ—á—É—Ç—Ç—è–º–∏
- –®—Ç—É—á–Ω–∞ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å: —É—Å–∫–ª–∞–¥–Ω–µ–Ω–Ω—è –ø—Ä–æ—Å—Ç–∏—Ö —Ä–µ—á–µ–π –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç—ñ

COGNITIVE_BIAS (–≤–∏–∫—Ä–∏–≤–ª–µ–Ω–Ω—è –º–∏—Å–ª–µ–Ω–Ω—è):
- Anchoring: –ø—Ä–∏–≤'—è–∑–∫–∞ –¥–æ –ø–µ—Ä—à–æ—ó —Ü–∏—Ñ—Ä–∏/–ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó
- Framing: –ø–æ–¥–∞—á–∞ –æ–¥–Ω—ñ—î—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –≤ —Ä—ñ–∑–Ω–æ–º—É —Å–≤—ñ—Ç–ª—ñ
- Loss aversion: –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –≤—Ç—Ä–∞—Ç–∞—Ö –∑–∞–º—ñ—Å—Ç—å –≤–∏–≥–æ–¥
- Social proof: "–≤—Å—ñ –∫–ª—ñ—î–Ω—Ç–∏ –∑–∞–¥–æ–≤–æ–ª–µ–Ω—ñ", –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —ñ–Ω—à–∏—Ö
- Authority bias: –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–∏, —Å—Ç–∞—Ç—É—Å, –ø–æ—Å–∞–¥–∏
- Confirmation bias: –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –≤–ª–∞—Å–Ω–æ—ó –¥—É–º–∫–∏, —ñ–≥–Ω–æ—Ä—É–≤–∞–Ω–Ω—è —Ñ–∞–∫—Ç—ñ–≤
- Sunk cost: "–≤–∂–µ —Å—Ç—ñ–ª—å–∫–∏ –≤–∫–ª–∞–ª–∏", –Ω–µ–º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –∑—É–ø–∏–Ω–∏—Ç–∏—Å—è
- FOMO: —Å—Ç—Ä–∞—Ö –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å
- Bandwagon: "–ø—Ä–∏—î–¥–Ω—É–π—Å—è –¥–æ –±—ñ–ª—å—à–æ—Å—Ç—ñ", –≥—Ä—É–ø–æ–≤–µ –º–∏—Å–ª–µ–Ω–Ω—è
- Availability heuristic: –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
- Overconfidence: –Ω–∞–¥–º—ñ—Ä–Ω–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å, –∑–∞—Ä–æ–∑—É–º—ñ–ª—ñ—Å—Ç—å
- Recency bias: –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –ø–æ–¥—ñ—è—Ö

RHETOLOGICAL_FALLACY (–ª–æ–≥—ñ—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏):
- Ad hominem: –∞—Ç–∞–∫–∞ –Ω–∞ –æ—Å–æ–±—É –∑–∞–º—ñ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ñ–≤
- Straw man: —Å–ø–æ—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ–∑–∏—Ü—ñ—ó –æ–ø–æ–Ω–µ–Ω—Ç–∞
- False dichotomy: —à—Ç—É—á–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–æ –¥–≤–æ—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤
- Appeal to emotion/fear: –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó –µ–º–æ—Ü—ñ—è–º–∏ –∑–∞–º—ñ—Å—Ç—å –ª–æ–≥—ñ–∫–∏
- Slippery slope: "—è–∫—â–æ —Ü–µ, —Ç–æ –æ–±–æ–≤'—è–∑–∫–æ–≤–æ —Å—Ç–∞–Ω–µ—Ç—å—Å—è —Ç–µ"
- Red herring: –≤—ñ–¥–≤–æ–ª—ñ–∫–∞–Ω–Ω—è –≤—ñ–¥ –æ—Å–Ω–æ–≤–Ω–æ—ó —Ç–µ–º–∏
- Hasty generalization: –ø–æ—Å–ø—ñ—à–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏ –∑ –º–∞–ª–æ—ó –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö
- Post hoc: "–ø—ñ—Å–ª—è —Ü—å–æ–≥–æ = —á–µ—Ä–µ–∑ —Ü–µ"
- Appeal to tradition: "–∑–∞–≤–∂–¥–∏ —Ç–∞–∫ —Ä–æ–±–∏–ª–∏"
- Burden of proof: –ø–µ—Ä–µ–∫–ª–∞–¥–∞–Ω–Ω—è —Ç—è–≥–∞—Ä—è –¥–æ–∫–∞–∑—ñ–≤
- Moving goalposts: –∑–º—ñ–Ω–∞ –∫—Ä–∏—Ç–µ—Ä—ñ—ó–≤ –ø–æ —Ö–æ–¥—É –¥–∏—Å–∫—É—Å—ñ—ó
- Cherry picking: –≤–∏–±—ñ—Ä–∫–æ–≤–∞ –ø–æ–¥–∞—á–∞ —Ñ–∞–∫—Ç—ñ–≤
- False equivalence: –ø—Ä–∏—Ä—ñ–≤–Ω—é–≤–∞–Ω–Ω—è –Ω–µ—Å—É–º—ñ—Ä–Ω–∏—Ö —Ä–µ—á–µ–π

–†–Ü–í–ù–Ü –°–ï–†–ô–û–ó–ù–û–°–¢–Ü:
1 = –õ–µ–≥–∫—ñ –Ω–∞—Ç—è–∫–∏, –º'—è–∫—ñ —Ç–µ—Ö–Ω—ñ–∫–∏ –≤–ø–ª–∏–≤—É, –Ω–µ–ø—Ä—è–º—ñ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó
2 = –ü–æ–º—ñ—Ä–Ω—ñ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó, —è–≤–Ω–∏–π –ø—Å–∏—Ö–æ–ª–æ–≥—ñ—á–Ω–∏–π —Ç–∏—Å–∫, —Å–≤—ñ–¥–æ–º—ñ –≤–∏–∫—Ä–∏–≤–ª–µ–Ω–Ω—è
3 = –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó, –≥—Ä—É–±–µ –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–Ω—è, —Ç–æ–∫—Å–∏—á–Ω—ñ —Ç–µ—Ö–Ω—ñ–∫–∏

–ü–†–ê–í–ò–õ–ê –ê–ù–ê–õ–Ü–ó–£:
‚úÖ –ê–Ω–∞–ª—ñ–∑—É–π –¢–Ü–õ–¨–ö–ò normalized_paragraphs[]
‚úÖ –í–∫–ª—é—á–∞–π –ø–æ–≤–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —É –ø–æ–ª–µ "text" –∫–æ–∂–Ω–æ–≥–æ highlight
‚úÖ –í—ñ–¥–¥–∞–≤–∞–π highlights —ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ (–æ–¥—Ä–∞–∑—É –∫–æ–ª–∏ –∑–Ω–∞—Ö–æ–¥–∏—à)
‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –ö–û–ñ–ï–ù –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø–æ–≤–Ω—ñ—Å—Ç—é - –≤—ñ–¥ –ø–µ—Ä—à–æ–≥–æ –¥–æ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
‚úÖ –ù–ï –ü–†–û–ü–£–°–ö–ê–ô –∂–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É. –ß–∏—Ç–∞–π –∫–æ–∂–Ω–µ —Ä–µ—á–µ–Ω–Ω—è, –∫–æ–∂–Ω—É —Ñ—Ä–∞–∑—É, –∫–æ–∂–Ω–µ —Å–ª–æ–≤–æ
‚úÖ –ó–Ω–∞–π–¥–∏ –í–°–Ü –º–æ–∂–ª–∏–≤—ñ –ø—Ä–æ–±–ª–µ–º–Ω—ñ –º–æ–º–µ–Ω—Ç–∏, –Ω–∞–≤—ñ—Ç—å –Ω–∞–π—Ç–æ–Ω—à—ñ –Ω–∞—Ç—è–∫–∏
‚úÖ –®—É–∫–∞–π –ø—Ä–∏—Ö–æ–≤–∞–Ω—ñ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ—ó: —Ç–æ–Ω, —ñ–º–ø–ª—ñ—Ü–∏—Ç–Ω—ñ –∑–∞–≥—Ä–æ–∑–∏, –ø—ñ–¥—Ç–µ–∫—Å—Ç–∏
‚úÖ –ê–Ω–∞–ª—ñ–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: —â–æ –ù–ï —Å–∫–∞–∑–∞–Ω–æ, —â–æ –∑–∞–º–æ–≤—á—É—î—Ç—å—Å—è
‚úÖ –ó–≤–µ—Ä—Ç–∞–π —É–≤–∞–≥—É –Ω–∞ –º–æ–≤—É —Ç—ñ–ª–∞ –≤ —Ç–µ–∫—Å—Ç—ñ: "—É—Å–º—ñ—Ö–Ω—É–≤—Å—è", "–ø–æ—Ö–º—É—Ä–æ –ø–æ–¥–∏–≤–∏–≤—Å—è"
‚úÖ –ù–µ –¥—É–±–ª—é–π –æ–¥–Ω–∞–∫–æ–≤—ñ/–ø–µ—Ä–µ–∫—Ä–∏–≤–Ω—ñ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏
‚úÖ –ö–æ–∂–µ–Ω JSON –º–∞—î –∑–∞–∫—ñ–Ω—á—É–≤–∞—Ç–∏—Å—å \\n
‚úÖ –ë—É–¥—å –ø–∞—Ä–∞–Ω–æ—ó–¥–∞–ª—å–Ω–æ —É–≤–∞–∂–Ω–∏–π –¥–æ –≤—Å—ñ—Ö —Ñ–æ—Ä–º –≤–ø–ª–∏–≤—É —Ç–∞ –º–∞–Ω—ñ–ø—É–ª—è—Ü—ñ–π
‚úÖ –ù–∞–≤—ñ—Ç—å –∑–≤–∏—á–∞–π–Ω—ñ —Ñ—Ä–∞–∑–∏ –º–æ–∂—É—Ç—å –º—ñ—Å—Ç–∏—Ç–∏ –º–∞–Ω—ñ–ø—É–ª—è—Ç–∏–≤–Ω–∏–π –ø—ñ–¥—Ç–µ–∫—Å—Ç - –ø–µ—Ä–µ–≤—ñ—Ä—è–π –≤—Å–µ
`.trim();
}

function buildUserPayload(paragraphs, clientCtx, limiter) {
  return {
    normalized_paragraphs: paragraphs.map((p) => ({
      index: p.index,
      text: p.text,
    })),
    client_context: clientCtx,
    constraints: { highlight_limit_per_1000_words: limiter },
    output_mode: 'ndjson',
  };
}

function supportsTemperature(model) {
  return !/^gpt-5($|[-:])/i.test(model);
}

// ===== Main Analysis Route =====
r.post('/', validateFileUpload, async (req, res) => {
  const analysisStartTime = performance.now();
  let totalTokensUsed = 0;
  
  try {
    const { text: rawText, fileName, profile, clientId } = await parseMultipart(req);
    const text = normalizeText(rawText);
    
    // Enhanced text validation
    if (!text || text.length < MIN_TEXT_LENGTH) {
      return res.status(400).json({ 
        error: `–¢–µ–∫—Å—Ç –∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–π. –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞: ${MIN_TEXT_LENGTH} —Å–∏–º–≤–æ–ª—ñ–≤`,
        minLength: MIN_TEXT_LENGTH,
        currentLength: text.length
      });
    }
    
    if (text.length > MAX_TEXT_LENGTH) {
      return res.status(400).json({ 
        error: `–¢–µ–∫—Å—Ç –∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞: ${MAX_TEXT_LENGTH.toLocaleString()} —Å–∏–º–≤–æ–ª—ñ–≤`,
        maxLength: MAX_TEXT_LENGTH,
        currentLength: text.length
      });
    }

    // Enhanced client validation and creation
    let finalClientId = clientId;
    if (!finalClientId && profile?.company) {
      const existingClient = dbGet(
        `SELECT id, company FROM clients WHERE company = ? LIMIT 1`,
        [profile.company]
      );
      if (existingClient) {
        finalClientId = existingClient.id;
      } else if (profile.company && profile.company.trim().length > 0) {
        // Auto-create client with validation
        try {
          const info = dbRun(
            `
            INSERT INTO clients(
              company, negotiator, sector, goal, decision_criteria, constraints,
              user_goals, client_goals, weekly_hours, offered_services, deadlines, notes,
              created_at, updated_at
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            `,
            [
              profile.company.trim(),
              profile.negotiator?.trim() || null,
              profile.sector?.trim() || null,
              profile.goal?.trim() || null,
              profile.criteria?.trim() || null,
              profile.constraints?.trim() || null,
              profile.user_goals?.trim() || null,
              profile.client_goals?.trim() || null,
              Number(profile.weekly_hours) || 0,
              profile.offered_services?.trim() || null,
              profile.deadlines?.trim() || null,
              profile.notes?.trim() || null,
              new Date().toISOString(),
              new Date().toISOString(),
            ]
          );
          finalClientId = info.lastID;
        } catch (dbError) {
          logError(dbError, { context: 'Auto-creating client', profile, ip: req.ip });
          return res.status(500).json({ error: '–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–ª—ñ—î–Ω—Ç–∞' });
        }
      }
    }

    if (!finalClientId) {
      return res.status(400).json({ 
        error: '–ü–æ—Ç—Ä—ñ–±–Ω–æ –≤–∫–∞–∑–∞—Ç–∏ –∫–ª—ñ—î–Ω—Ç–∞ –∞–±–æ –∫–æ–º–ø–∞–Ω—ñ—é',
        required: 'client_id –∞–±–æ profile.company'
      });
    }

    const paragraphs = splitToParagraphs(text);
    
    const clientCtx = {
      about_client: {
        company: profile?.company || '',
        negotiator: profile?.negotiator || '',
        sector: profile?.sector || '',
      },
      decision_criteria: profile?.criteria || '',
      constraints: profile?.constraints || '',
      user_goals: profile?.user_goals || profile?.goal || '',
      client_goals: profile?.client_goals || '',
      weekly_hours: Number(profile?.weekly_hours) || 0,
      offered_services: profile?.offered_services || '',
      deadlines: profile?.deadlines || '',
      notes: profile?.notes || '',
    };

    // More accurate input token calculation
    const textTokens = estimateTokens(text);
    const systemPromptTokens = estimateTokens(buildSystemPrompt());
    const userPayloadTokens = estimateTokens(JSON.stringify(buildUserPayload(paragraphs, clientCtx, MAX_HIGHLIGHTS_PER_1000_WORDS)));
    const approxTokensIn = textTokens + systemPromptTokens + userPayloadTokens + 200; // buffer
    
    totalTokensUsed += approxTokensIn;
    
    // Check token limits before processing
    await addTokensAndCheck(approxTokensIn);

    // Check if OpenAI client is available
    if (!openaiClient) {
      return res.status(503).json({
        error: 'AI —Å–µ—Ä–≤—ñ—Å —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é OpenAI API –∫–ª—é—á–∞.',
        code: 'AI_SERVICE_UNAVAILABLE',
        timestamp: new Date().toISOString()
      });
    }

    // SSE headers
    res.status(200);
    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');
    res.setHeader('Cache-Control', 'no-cache, no-transform');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('X-Accel-Buffering', 'no');

    const heartbeat = setInterval(() => {
      res.write(': ping\n\n');
    }, 15000);

    req.on('close', () => {
      clearInterval(heartbeat);
      try { res.end(); } catch {}
    });

    const sendLine = (obj) => res.write(`data: ${JSON.stringify(obj)}\n\n`);

    const rawHighlights = [];
    let summaryObj = null;
    let barometerObj = null;

    // Enhanced OpenAI client availability check with recovery
    if (!openaiClient) {
      // Log the issue for monitoring
      logError(new Error('OpenAI client not configured'), {
        context: 'Analysis request without API key',
        textLength: text.length,
        clientId: finalClientId,
        ip: req.ip
      });
      
      // Return structured error instead of fallback
      clearInterval(heartbeat);
      return res.status(503).json({
        error: 'AI —Å–µ—Ä–≤—ñ—Å —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.',
        code: 'AI_SERVICE_UNAVAILABLE',
        details: 'OpenAI API key not configured',
        timestamp: new Date().toISOString(),
        retry_after: 60 // seconds
      });
    }

    const system = buildSystemPrompt();
    const user = JSON.stringify(
      buildUserPayload(paragraphs, clientCtx, MAX_HIGHLIGHTS_PER_1000_WORDS)
    );

    const reqPayload = {
      model: MODEL,
      stream: true,
      messages: [
        { role: 'system', content: system + '\n–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –ë–ï–ó ``` —Ç–∞ –±—É–¥—å-—è–∫–æ–≥–æ –º–∞—Ä–∫–∞–ø—É.' },
        { role: 'user', content: user },
      ],
      stop: ['```','</artifacts>','</artifact>'],
      max_tokens: 4000,
      top_p: 0.9
    };

    if (supportsTemperature(MODEL)) {
      reqPayload.temperature = Number(process.env.OPENAI_TEMPERATURE ?? 0.1);
    }
    
    // Encourage complete analysis
    reqPayload.presence_penalty = 0.1;
    reqPayload.frequency_penalty = 0.1;

    // Enhanced request handling with progressive timeout
    const controller = new AbortController();
    const REQUEST_TIMEOUT = process.env.NODE_ENV === 'production' ? 180000 : 120000; // 3min prod, 2min dev
    
    const timeout = setTimeout(() => {
      controller.abort(new Error('Request timeout after ' + (REQUEST_TIMEOUT/1000) + 's'));
    }, REQUEST_TIMEOUT);
    
    req.on('close', () => {
      clearTimeout(timeout);
      controller.abort(new Error('Request closed by client'));
    });
    
    // Connection heartbeat with early termination detection
    const connectionCheck = setInterval(() => {
      if (req.destroyed || req.closed) {
        clearTimeout(timeout);
        controller.abort(new Error('Connection lost'));
        clearInterval(connectionCheck);
      }
    }, 5000);
    
    let stream;
    let retryCount = 0;
    const maxRetries = process.env.NODE_ENV === 'production' ? 3 : 1;
    
    while (retryCount <= maxRetries) {
      try {
        // Add retry delay for subsequent attempts
        if (retryCount > 0) {
          await new Promise(resolve => setTimeout(resolve, Math.min(1000 * Math.pow(2, retryCount), 10000)));
        }
        
        stream = await openaiClient.chat.completions.create(reqPayload);
        
        clearTimeout(timeout);
        clearInterval(connectionCheck);
        break; // Success, exit retry loop
        
      } catch (apiError) {
        retryCount++;
        
        // Check if it's a retryable error
        const isRetryable = apiError.status >= 500 || 
                          apiError.status === 429 || 
                          apiError.code === 'ECONNRESET' ||
                          apiError.code === 'ETIMEDOUT';
                          
        if (retryCount > maxRetries || !isRetryable) {
          clearTimeout(timeout);
          clearInterval(connectionCheck);
          throw apiError;
        }
        
        logError(apiError, {
          context: `OpenAI API retry ${retryCount}/${maxRetries}`,
          model: MODEL,
          textLength: text.length,
          isRetryable,
          ip: req.ip
        });
      }
    }
    if (!stream) {
      clearInterval(heartbeat);
      return res.status(503).json({
        error: '–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑ º—î–¥–Ω–∞–Ω–Ω—è –∑ AI —Å–µ—Ä–≤—ñ—Å–æ–º –ø—ñ—Å–ª—è –∫—ñ–ª—å–∫–æ—Ö —Å–ø—Ä–æ–±',
        code: 'AI_CONNECTION_FAILED',
        retries: maxRetries,
        timestamp: new Date().toISOString()
      });
    }
    // Stream processing with enhanced error handling
    try {
      // –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –≤–∏–¥–æ–±—É–≤–∞–Ω–Ω—è JSON-–æ–±'—î–∫—Ç—ñ–≤
      const ALLOWED_TYPES = new Set(['highlight','summary','barometer']);

      // –î—ñ—Å—Ç–∞—î –∑ –±—É—Ñ–µ—Ä–∞ –≤—Å—ñ –ø–æ–≤–Ω—ñ JSON-–æ–±'—î–∫—Ç–∏ (brace-matching), –ø–æ–≤–µ—Ä—Ç–∞—î [objs, rest]
      function extractJsonObjects(buffer) {
        const out = [];
        let i = 0;
        const n = buffer.length;
        let depth = 0;
        let start = -1;
        let inStr = false;
        let esc = false;

        while (i < n) {
          const ch = buffer[i];

          if (inStr) {
            if (esc) { esc = false; }
            else if (ch === '\\') { esc = true; }
            else if (ch === '"') { inStr = false; }
            i++; continue;
          }

          if (ch === '"') { inStr = true; i++; continue; }

          if (ch === '{') {
            if (depth === 0) start = i;
            depth++;
          } else if (ch === '}') {
            depth--;
            if (depth === 0 && start >= 0) {
              const raw = buffer.slice(start, i + 1);
              out.push(raw);
              start = -1;
            }
          }

          i++;
        }

        const rest = depth === 0 ? '' : buffer.slice(start >= 0 ? start : n);
        return [out, rest];
      }

      // –°–∞–Ω—ñ—Ç–∏–∑–∞—Ü—ñ—è: –ø—Ä–∏–±—Ä–∞—Ç–∏ –±–µ–∫—Ç–∏–∫–∏, –º—ñ—Ç–∫–∏ ```json —Ç–∞ –∫–µ—Ä—ñ–≤–Ω—ñ —Å–∏–º–≤–æ–ª–∏ (–∫—Ä—ñ–º \n\t)
      const sanitizeChunk = (s) =>
        s
          .replace(/```(?:json)?/gi, '')
          .replace(/<\/?artifact[^>]*>/gi, '')
          .replace(/[\u0000-\u0008\u000B\u000C\u000E-\u001F]/g, '');

      let buffer = '';
      let chunkCount = 0;
      const maxChunks = 2000; // Prevent infinite processing
      
      for await (const part of stream) {
        if (++chunkCount > maxChunks) {
          logError(new Error('Too many chunks received from AI stream'), {
            chunkCount,
            bufferLength: buffer.length
          });
          break;
        }
        
        const delta = part.choices?.[0]?.delta?.content || '';
        if (!delta) continue;

        buffer += sanitizeChunk(delta);

        // –í–∏—Ç—è–≥—É—î–º–æ –≤—Å—ñ –∑–∞–≤–µ—Ä—à–µ–Ω—ñ JSON-–æ–±'—î–∫—Ç–∏ –∑ –±—É—Ñ–µ—Ä–∞
        const [rawObjs, rest] = extractJsonObjects(buffer);
        buffer = rest;

        for (const raw of rawObjs) {
          try {
            const obj = JSON.parse(raw);

            // –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—á—ñ–∫—É–≤–∞–Ω—ñ —Ç–∏–ø–∏
            if (!obj || !ALLOWED_TYPES.has(obj.type)) continue;

            if (obj.type === 'highlight') {
              rawHighlights.push(obj);
              sendLine(obj);
            } else if (obj.type === 'summary') {
              summaryObj = obj;
            } else if (obj.type === 'barometer') {
              barometerObj = obj;
            }
          } catch (e) {
            // –¢–∏—Ö–æ —ñ–≥–Ω–æ—Ä—É—î–º–æ –±–∏—Ç—ñ –æ–±'—î–∫—Ç–∏
          }
        }
      }
    } catch (streamError) {
      clearInterval(heartbeat);
      
      logError(streamError, {
        context: 'Stream processing failed',
        clientId: finalClientId,
        textLength: text.length
      });
      
      if (!res.headersSent) {
        return res.status(503).json({
          error: '–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ AI —Å–µ—Ä–≤—ñ—Å—É',
          code: 'AI_STREAM_ERROR',
          timestamp: new Date().toISOString()
        });
      }
      return;
    }

    // Remove artificial highlight limits to find all problems
    const merged = mergeOverlaps(rawHighlights, paragraphs);

    sendLine({ type: 'merged_highlights', items: merged });
    if (summaryObj) sendLine(summaryObj);
    if (barometerObj) sendLine(barometerObj);

    // More accurate output token estimation based on highlights and summary
    let outputTokens = 500; // Base system response
    outputTokens += merged.length * 50; // ~50 tokens per highlight
    if (summaryObj) outputTokens += 300; // Summary tokens
    if (barometerObj) outputTokens += 100; // Barometer tokens
    
    totalTokensUsed += outputTokens;
    await addTokensAndCheck(outputTokens);
    
    // Log AI usage for monitoring
    logAIUsage(totalTokensUsed, MODEL, 'text_analysis');
    
    const analysisDuration = performance.now() - analysisStartTime;
    logPerformance('Complete Analysis', analysisDuration, {
      textLength: text.length,
      tokensUsed: totalTokensUsed,
      highlightsFound: merged.length,
      clientId: finalClientId
    });

    // Generate title for analysis
    const title = fileName
      ? `–ê–Ω–∞–ª—ñ–∑: ${fileName}`
      : `–ê–Ω–∞–ª—ñ–∑ –≤—ñ–¥ ${new Date().toLocaleDateString('uk-UA')}`;

    // Save to DB with client_id
    const result = dbRun(
      `
      INSERT INTO analyses(
        client_id, title, source, original_filename, original_text, tokens_estimated, 
        highlights_json, summary_json, barometer_json
      ) VALUES (?,?,?,?,?,?,?,?,?)
      `,
      [
        finalClientId,
        title,
        fileName ? 'file' : 'text',
        fileName || null,
        text.substring(0, 1000), // Save first 1000 chars for preview
        totalTokensUsed,
        JSON.stringify(merged),
        JSON.stringify(summaryObj || null),
        JSON.stringify(barometerObj || null),
      ]
    );

    sendLine({ 
      type: 'analysis_saved', 
      id: result.lastID, 
      client_id: finalClientId,
      original_text: text 
    });
    
    // Send complete signal to frontend
    sendLine({ 
      type: 'complete', 
      analysis_id: result.lastID 
    });
    
    res.write('event: done\ndata: "ok"\n\n');
    res.end();
  } catch (err) {
    const analysisDuration = performance.now() - analysisStartTime;
    
    logError(err, {
      context: 'Analysis route error',
      duration: analysisDuration,
      tokensUsed: totalTokensUsed,
      ip: req.ip,
      userAgent: req.get('User-Agent')
    });
    
    try {
      if (!res.headersSent) {
        const isRateLimit = err.message.includes('–õ—ñ–º—ñ—Ç');
        const statusCode = isRateLimit ? 429 : 500;
        
        res.status(statusCode).json({ 
          error: err.message || '–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∞–Ω–∞–ª—ñ–∑—É',
          code: isRateLimit ? 'RATE_LIMIT_EXCEEDED' : 'ANALYSIS_ERROR',
          timestamp: new Date().toISOString()
        });
      } else {
        res.write(`event: error\ndata: ${JSON.stringify({
          error: err.message,
          timestamp: new Date().toISOString()
        })}\n\n`);
        res.end();
      }
    } catch (finalError) {
      logError(finalError, { context: 'Final error handler' });
    }
  }
});

export default r;